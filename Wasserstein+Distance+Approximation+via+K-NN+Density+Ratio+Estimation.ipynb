{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particle Mover GANs & Adaptible Hybrid Noise Generators\n",
    "\n",
    "Author: [Kai Londenberg](Kai.Londenberg@googlemail.com) - 2018\n",
    "\n",
    "The recent success story of WGAN models for learning deep generative models is based on a certain formulation of adversarial training which can be interpreted as the minimization of the Wasserstein Distance $ W $ , also known as Earth-Mover Distance between a parametric generated distribution $ P_{\\theta} $ and a fixed empirical distribution $ P_r $.\n",
    "\n",
    "$ P_{\\theta} $ in the context of recent generative models such as GAN and VAE variants is usually generated by sampling a continuous random vector $ Z $ from a known probability distribution, and transforming the generated samples using a trainable  neural network function $ g_\\theta $ so that $ P_\\theta = g_\\theta(Z) $ \n",
    "\n",
    "The learning objective in this context is to **learn a distribution** via minimization of some kind of distance or divergence between $ P_r $ and $ P_\\theta $. We will call this distance function $ d(P_r, P_\\theta) $\n",
    "\n",
    "[Martin Arjovsky, Soumith Chintala and Léon Bottou showed](https://arxiv.org/abs/1701.07875) that the choice of this distance function, with the most common choice being the KL-Divergence, is of paramount importance for the ability of a gradient-based optimization method to succeed in letting $ P_\\theta $ converge towards $ P_r $ as the training optimizes the objective $ \\min_{\\theta} d(P_r, P_\\theta) $\n",
    "\n",
    "In this context, they proved that the minimization of the so-called Wasserstein Distance $ W $, also known as Earth-Mover Distance is ideal, for reasons detailed below.  \n",
    "\n",
    "To introduce the Wasserstein Distance, we define $ \\prod(P_\\theta,P_r) $ as the set of all joint distributions $ \\lambda $ whose marginal distributions are $ P_\\theta $ and $ P_r $ respectively. Then the Earth-Mover or Wasserstein Distance is defined as\n",
    "\n",
    "$$\n",
    "W(P_\\theta, P_r) = \\inf_{\\lambda \\in \\prod(P_\\theta,P_r)} \\mathbb{E}_{(x,y) \\sim \\lambda}[\\parallel x-y \\parallel]\n",
    "$$\n",
    "\n",
    "This has been described as a measure of how much probability mass would need to be moved at minimum to convert one distribution to the other. Therefore the name Earth-Mover distance. See [Wasserstein GAN Read Through](https://www.alexirpan.com/2017/02/22/wasserstein-gan.html) for a good explanation.\n",
    "\n",
    "The Wasserstein Distance is very important, given that the paper also provided proofs that under some mild conditions:\n",
    "\n",
    " * If $ P_\\theta $ is a smooth function of $ \\theta $, then $ W(P_\\theta, P_r) $ is also smooth over $ \\theta $.\n",
    " * The above is not generally true for KL-Divergence and other Divergences or distribution distance metrics.\n",
    " * $ W(P_\\theta, P_r) \\rightarrow 0 $ implies convergence in probability of $ P_\\theta$ and $ P_r $ \n",
    " *  Consequently, $ W(P_\\theta, P_r) \\rightarrow 0 $ implies $ KL(P_\\theta, P_r) \\rightarrow 0 $ and $ {KL}(P_r, P_\\theta) \\rightarrow 0 $.\n",
    " \n",
    "\n",
    "In general, the Wasserstein distance cannot be calculated exactly. So we need to approximate it, and the WGAN paper describes a way of how to achieve this with great experimental results by exploiting the so called [Kantorovich-Rubinstein duality](https://en.wikipedia.org/wiki/Wasserstein_metric#Dual_representation_of_W1) of the Wasserstein Metric.\n",
    "\n",
    "This can be achieved by a slight alteration of GAN training. The subsequent training algorithm, called a WGAN has been experimentally evaluated (and further refined in subsequent papers) to great success,\n",
    "\n",
    "The planned contribution of this paper is to develop an alternative and maybe more easily applicable method to achieve the same goal, without the necessity (but with possibility) of adversarial training, with potential applicability to mixed discrete and continuous distributions (so Z may be completely or partially discrete and might even have an intractable density), and with the potential to solve the mode collapse problem of GAN training.\n",
    "\n",
    "The idea for the matching paired samples has been strongly influenced by the Paper [Wang Q Kulkarni S Verdú S: A Nearest-Neighbor Approach to Estimating Divergence between Continuous Random Vectors](https://www.princeton.edu/~verdu/nearest.neigh.pdf) which uses a similar approach to estimate divergences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonparametric Density Estimate over a Latent Manifold\n",
    "\n",
    "The following is an variant of the approach of [D. O. Loftsgaarden, C. P. Quesenberry: A nonparametric estimate of a multivariate density function](https://projecteuclid.org/euclid.aoms/1177700079).\n",
    "\n",
    "Let $P_x$ be a random variable with range $ \\mathbb{R}^q $ and $ \\{ x_i\\}_{i=1}^{n} $ be a list of i.i.d, samples with $ x_i \\sim P_x $. Furthermore, let $ d: (\\mathbb{R}^q,\\mathbb{R}^q)  \\mapsto [ 0, \\infty ) $  be a smooth and differentiable function, which we will call the natural sample distance metric and assume to be given or learnable. \n",
    "\n",
    "We assume the random variable $P_x$ to be functionally related to this natural distance metric.\n",
    "\n",
    "This functional relation can be specified as follows. We assume that the natural distance metric internally maps two points on space $ \\mathbb{R}^q $ to a latent manifold $ \\mathbb{A} $ and and then computes their distance on that space. Therefore, we introduce mapping $ m : \\mathbb{R}^q \\mapsto \\mathbb{A} $ and latent distance metric $ d_A : \\mathbb{A}x\\mathbb{A} \\mapsto [ 0, \\infty ) $ and define $ d(x_i,x_j) = d_A(m(x_i), m(x_j)) $. We also define the inverse mapping $ s : \\mathbb{A} \\mapsto \\mathbb{R}^q $ with $ m := s^{-1} $.\n",
    "\n",
    "We further assume existence of Lebesgue measure $ \\mu(A) $ over $ A \\subseteq \\mathbb{A} $ which is determined by $ d_A $. We further define $ \\mu_P(A) = \\frac{\\mu(A)}{Z} $ to be a normalized probability measure based on $ \\mu $, e.g. we define $ Z = \\mu(\\mathbb{A}) $. Note that $ Z $ is considered to be unknown. \n",
    "\n",
    "The triplet $ (\\mathbb{A}, \\mathbb{B}_A, \\mu_P ) $ forms a probability space under Lebesgue measure with $ \\mathbb{B}_A $ being the Borel-Sets of $ \\mathbb{A} $. We will call this our latent probability space. The random variable $ P_x $ is then defined as a Borel-Measurable, vector-valued function over this probability space with $ P_x(X) = \\mu_P(s(X)) ; X \\subseteq \\mathbb{R}^q $\n",
    "\n",
    "Being a manifold, $ \\mathbb{A} $ can be considered [locally w-euclidean](https://topospaces.subwiki.org/wiki/Locally_Euclidean_space) with  unknown but finite dimensionality $ w  $. As such, we assume that within the $ \\epsilon $ neighbourhood of any point $ a_i \\in \\mathbb{A} $, the following property holds:\n",
    "\n",
    "$\n",
    "\\forall r <= \\epsilon: A = \\{ a ; d_A(a,a_i)<r \\} \\Rightarrow \\mu(A) \\approxeq V_w(r)\n",
    "$\n",
    "\n",
    "where V_w(r) is the radius of a hypersphere in $ \\mathbb{R}^w $. Also note that $ A \\in \\mathbb{B}_A$. \n",
    "\n",
    "That is, we assume the measure $ \\mu(A) $ to be locally approximated by the volume of a w-dimensional hypersphere around point $ a_i $ with a radius defined over the metric $ d_A $ as long as we stay within an $\\epsilon$-neighbourhood. The intuition being, that probability measures can be considered to be generalizations of the concepts of length, area or volume in euclidean spaces.\n",
    "\n",
    "By extension, we have for every point within the $ \\epsilon $ neighbourhood of $ x_i \\in \\mathbb{R}^q $\n",
    "\n",
    "$\n",
    "\\forall r <= \\epsilon: X = \\{ x ; d(x,x_i)<r \\} \\Rightarrow \\mu(m(X)) \\approxeq V_w(r)\n",
    "$\n",
    "\n",
    "If we define the set $ H(x,r) := \\{x : x \\in \\mathbb{R}^q \\land d(x_i,x)<r \\} $ and set $ P_x(X \\subseteq \\mathbb{R}^q ) := \\mu_A(m(X \\subseteq \\mathbb{R}^q )) $, we arrive at\n",
    "\n",
    "$$\n",
    "P_x(H(x_i,d(x_i,x_j)) \\approxeq \\frac{V_w(r)}{Z}\n",
    "$$\n",
    "\n",
    "We can furthermore define the density of $P_x$ as $ p_x(x) = \\lim_{x_j \\rightarrow x_i} P_x(H(x_i,d(x_i, x_j)) = \\lim_{r \\rightarrow 0} P_x(H(x_i,r)) $. \n",
    "\n",
    "If we sample $ \\{ x_1, ..., x_n \\} $ i.i.d with all $ x_i \\sim P_x $ the expected number of samples with $ d(x, x_i) \\lt r \\leq\\epsilon $ around an arbitrary point x can be calculated as\n",
    "\n",
    "$$\n",
    "E[\\vert\\{ x_i : d(x, x_i)<=r\\}\\vert] \\approxeq P_x(H(x,r)) \\cdot n = \\frac{E_{( \\hat{x} \\sim P_x \\,\\land\\, \\hat{x}\\in H(x,r) )}[p_x(\\hat{x})] \\cdot V(r) \\cdot n}{Z}\n",
    "$$\n",
    "\n",
    "Which gives us a way to estimate the density around a point x given an empirical list of samples for a given radius r:\n",
    "\n",
    "$$\n",
    "\\hat{p}_x(x,r) = \\frac{\\vert\\{ x_i : d(x, x_i)<=r\\}\\vert \\cdot Z }{V(r) \\cdot n}\n",
    "$$\n",
    "\n",
    "Assuming we can also calculate a running Monte-Carlo estimate of Z, we can derive our density estimate based on a potentially learned metric function $d$ and dimensionality $w$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: A hypersphere in a $ w $ dimensional space with radius $ r $ has the volume\n",
    "\n",
    "$$\n",
    "V_w(r) = \\frac{r^w \\pi^{{\\frac{w}{2}}}}{\\Gamma(\\frac{w}{2}+1)}\n",
    "$$\n",
    "\n",
    "where $ \\Gamma $ is the gamma function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-Batch Wasserstein Distance Estimator\n",
    "\n",
    "We will now construct a Mini-Batch estimator for the Wasserstein distance. We will recall the definition:\n",
    "\n",
    "Define $ \\prod(P_x,P_y) $ as the set of all joint distributions $ \\lambda $ whose marginal distributions are $ P_x $ and $ P_y $ respectively. Then the Earth-Mover or Wasserstein Distance is defined as\n",
    "\n",
    "$$\n",
    "W(P_x, P_y) = \\inf_{\\lambda \\in \\prod(P_x,P_y)} E_{(x,y) \\sim \\lambda}[d(x,y)]\n",
    "$$\n",
    "\n",
    "We will therefore introduce a second distribution $ P_y $ which we can also sample from $ \\{ y_i, ..., y_n \\} $ with $ y_i \\in \\mathbb{R}^q \\sim P_y $ defined over the same. \n",
    "\n",
    "in our case, we have finite lists of samples with point density estimates available for both distributions at each of the samples. We can precompute all of these pointwise densities and the matrix of pairwise distances between samples. After proper normalization of the pointwise densities, we can then treat the densities as discrete probability mass and [compute the exact discrete solution of the Earth Mover Distance](https://en.wikipedia.org/wiki/Earth_mover%27s_distance#Computing_the_EMD). \n",
    "\n",
    "This requires solving the so called Transportation Problem and can be done in polynomial time. In Python, there is at least one implementation available as part of the MIT Licensed [Python Optimal Transport Library by Rémi Flamary and Nicolas Courty](https://github.com/rflamary/POT) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Approach for Adaptible Hybrid Noise Generator\n",
    "\n",
    "Interestingly, for a given a solution of the transport problem, there are two ways to increase or decrease the density of a sample at a given point. One variant is to pull samples to, or push them away from a given point. Another variant is to directly increase or decrease the probability mass of samples at a given point. Both might lead to augmenting learning strategies.\n",
    "\n",
    "Pulling or pushing samples can be achieved by exploiting the gradient with respect to the distance metric. Decreasing or Increasing the overall probability of a given sample might be achieved by directly modifying the probability mass of the noise underlying a generated sample.\n",
    "\n",
    "Most importantly in this context, if we assume the natural distance metric to work on some kind of latent manifold, we cannot trust the direction of gradient updates over long ranges, as it could even pull us towards regions of low or even into regions of zero density. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import no_grad, Variable\n",
    "from torch.nn.utils.clip_grad import clip_grad_norm\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import ot # Python Optimal Transport Library\n",
    "import scipy.stats as scistats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMix(object):\n",
    "    \n",
    "    def __init__(self, weights, dists):\n",
    "        self.weights = weights\n",
    "        self.dists = dists\n",
    "        \n",
    "    def rvs(self, n):\n",
    "        distchoice = np.nonzero(np.random.multinomial(1, self.weights, n))[1]\n",
    "        values = [ self.dists[i].rvs(1)[0] for i in distchoice]\n",
    "        return np.array(values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_r = MyMix([0.3, 0.1, 0.45, 0.15], [scistats.beta(1,100), scistats.beta(200,1), scistats.halfnorm(0.6, 0.05)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAE21JREFUeJzt3W2QneV93/HvL2Ds2HEsHhaG6qEi\nYyVNxjMmdAcr9UzqWE7GQAfxAjJ4miIzmqqTUjcJmdZq+8J9egF9ImGaIVUjNyKT2BAaB41NkzIC\nj9tORC0MwTzEw5oQaSsVKQaUZhgnIfn3xbkUdsSu9l7tObvaS9/PzM657+u+zjn/ixW/c+117nOf\nVBWSpH59x2oXIEmaLINekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1LkLV7sAgMsu\nu6w2b9682mVI0pry5JNP/mFVTS3W75wI+s2bN3Po0KHVLkOS1pQkfzCkn0s3ktQ5g16SOmfQS1Ln\nDHpJ6tygoE/yM0meS/Jsks8leVeSq5I8keTFJA8kuaj1fWfbn2nHN09yAJKkM1s06JOsB/4hMF1V\nHwAuAG4F7gbuqaotwGvAznaXncBrVfV+4J7WT5K0SoYu3VwIfGeSC4F3A8eAjwIPteP7gJva9va2\nTzu+LUnGU64kaakWDfqq+j/AvwMOMwr4k8CTwOtV9WbrNgusb9vrgSPtvm+2/peOt2xJ0lBDlm4u\nZjRLvwr4K8B7gOvm6Xrqy2fnm72/7Ytpk+xKcijJoRMnTgyvWJK0JEM+Gfsx4Per6gRAkt8A/gaw\nLsmFbda+ATja+s8CG4HZttTzPuDV0x+0qvYAewCmp6f9hnLpNJt3f2ne9pfvumGFK9FaN2SN/jCw\nNcm721r7NuB54HHg5tZnB/Bw297f9mnHH6sqg1ySVsmQNfonGL2p+jXg6+0+e4BPA3cmmWG0Br+3\n3WUvcGlrvxPYPYG6JUkDDbqoWVV9BvjMac0vAdfO0/fbwC3LL02SNA5+MlaSOmfQS1LnDHpJ6pxB\nL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SercoGvdSDr3eVljLcQZvSR1zqCXpM65\ndCOtMQst0UgLcUYvSZ0z6CWpc4sGfZLvS/L0nJ8/SvLTSS5J8miSF9vtxa1/ktybZCbJM0mumfww\nJEkLGfKdsd+oqqur6mrgrwNvAF9g9F2wB6pqC3CAt74b9jpgS/vZBdw3icIlScMsdelmG/DNqvoD\nYDuwr7XvA25q29uB+2vkILAuyZVjqVaStGRLPevmVuBzbfuKqjoGUFXHklze2tcDR+bcZ7a1HVtO\noZLOjh+k0uAZfZKLgBuBX1+s6zxtNc/j7UpyKMmhEydODC1DkrRES1m6uQ74WlW90vZfObUk026P\nt/ZZYOOc+20Ajp7+YFW1p6qmq2p6ampq6ZVLkgZZStB/greWbQD2Azva9g7g4Tntt7Wzb7YCJ08t\n8UiSVt6gNfok7wZ+FPh7c5rvAh5MshM4DNzS2h8BrgdmGJ2hc/vYqpUkLdmgoK+qN4BLT2v7FqOz\ncE7vW8AdY6lOkrRsfjJWkjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BL\nUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOjco6JOsS/JQkt9L8kKSH0pySZJHk7zY\nbi9ufZPk3iQzSZ5Jcs1khyBJOpOhM/qfB36rqv4a8EHgBWA3cKCqtgAH2j7AdcCW9rMLuG+sFUuS\nlmTRoE/y3cAPA3sBqupPq+p1YDuwr3XbB9zUtrcD99fIQWBdkivHXrkkaZAhM/rvAU4A/yXJU0l+\nKcl7gCuq6hhAu7289V8PHJlz/9nWJklaBRcO7HMN8KmqeiLJz/PWMs18Mk9bva1TsovR0g6bNm0a\nUIYkrV2bd39p3vaX77ph4s89ZEY/C8xW1RNt/yFGwf/KqSWZdnt8Tv+Nc+6/ATh6+oNW1Z6qmq6q\n6ampqbOtX5K0iEWDvqr+L3Akyfe1pm3A88B+YEdr2wE83Lb3A7e1s2+2AidPLfFIklbekKUbgE8B\nv5rkIuAl4HZGLxIPJtkJHAZuaX0fAa4HZoA3Wl9J0ioZFPRV9TQwPc+hbfP0LeCOZdYlSRoTPxkr\nSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLU\nOYNekjpn0EtS5wx6SeqcQS9JnRsU9EleTvL1JE8nOdTaLknyaJIX2+3FrT1J7k0yk+SZJNdMcgCS\npDNbyoz+R6rq6qo69ZWCu4EDVbUFOND2Aa4DtrSfXcB94ypWkrR0y1m62Q7sa9v7gJvmtN9fIweB\ndUmuXMbzSJKWYWjQF/DfkzyZZFdru6KqjgG028tb+3rgyJz7zrY2SdIquHBgvw9X1dEklwOPJvm9\nM/TNPG31tk6jF4xdAJs2bRpYhiRpqQbN6KvqaLs9DnwBuBZ45dSSTLs93rrPAhvn3H0DcHSex9xT\nVdNVNT01NXX2I5AkndGiQZ/kPUnee2ob+DHgWWA/sKN12wE83Lb3A7e1s2+2AidPLfFIklbekKWb\nK4AvJDnV/9eq6reSfBV4MMlO4DBwS+v/CHA9MAO8Adw+9qolLdvm3V9aUv+X77phQpVo0hYN+qp6\nCfjgPO3fArbN017AHWOpTpK0bH4yVpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5\ng16SOjf06pWSpEUs9bISK8UZvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnRsc9EkuSPJU\nki+2/auSPJHkxSQPJLmotb+z7c+045snU7okaYilzOh/Cnhhzv7dwD1VtQV4DdjZ2ncCr1XV+4F7\nWj9J0ioZFPRJNgA3AL/U9gN8FHioddkH3NS2t7d92vFtrb8kaRUMndH/HPCPgb9o+5cCr1fVm21/\nFljfttcDRwDa8ZOtvyRpFSx6rZskfws4XlVPJvnIqeZ5utaAY3MfdxewC2DTpk2DipW0es50HZeX\n77phBSvRUg2Z0X8YuDHJy8DnGS3Z/BywLsmpF4oNwNG2PQtsBGjH3we8evqDVtWeqpququmpqall\nDUKStLBFg76q/klVbaiqzcCtwGNV9beBx4GbW7cdwMNte3/bpx1/rKreNqOXJK2M5ZxH/2ngziQz\njNbg97b2vcClrf1OYPfySpQkLceSrkdfVV8Gvty2XwKunafPt4FbxlCbJGkM/OIRSVqic/ULRhbi\nJRAkqXMGvSR1zqCXpM4Z9JLUOYNekjq35s+6Wejdbz+SLUkjzuglqXMGvSR1zqCXpM4Z9JLUOYNe\nkjq35s+6kaRJWWvXtFmIM3pJ6pxBL0mdM+glqXMGvSR1btGgT/KuJP87ye8meS7Jv2jtVyV5IsmL\nSR5IclFrf2fbn2nHN092CJKkMxkyo/8T4KNV9UHgauDjSbYCdwP3VNUW4DVgZ+u/E3itqt4P3NP6\nSZJWyaJBXyN/3Hbf0X4K+CjwUGvfB9zUtre3fdrxbUkytoolSUsyaI0+yQVJngaOA48C3wRer6o3\nW5dZYH3bXg8cAWjHTwKXjrNoSdJwg4K+qv68qq4GNgDXAt8/X7d2O9/svU5vSLIryaEkh06cODG0\nXknSEi3prJuqeh34MrAVWJfk1CdrNwBH2/YssBGgHX8f8Oo8j7WnqqaranpqaursqpckLWrRSyAk\nmQL+rKpeT/KdwMcYvcH6OHAz8HlgB/Bwu8v+tv877fhjVfW2Gb0knSt6udTBQoZc6+ZKYF+SCxj9\nBfBgVX0xyfPA55P8a+ApYG/rvxf4lSQzjGbyt06g7kX5zVOSNLJo0FfVM8APztP+EqP1+tPbvw3c\nMpbqJK0JTqzObX4yVpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1Ln\nhlzrpitnuniRH9eW1KPzLuglrRyvgXNucOlGkjpn0EtS5wx6Seqca/SSzhu9f5PUQpzRS1LnFg36\nJBuTPJ7khSTPJfmp1n5JkkeTvNhuL27tSXJvkpkkzyS5ZtKDkCQtbMjSzZvAz1bV15K8F3gyyaPA\nJ4EDVXVXkt3AbuDTwHXAlvbzIeC+ditJgKddrrRFZ/RVdayqvta2/x/wArAe2A7sa932ATe17e3A\n/TVyEFiX5MqxVy5JGmRJa/RJNjP6ovAngCuq6hiMXgyAy1u39cCROXebbW2SpFUw+KybJN8F/Ffg\np6vqj5Is2HWetprn8XYBuwA2bdo0tIyJ8s9JST0aFPRJ3sEo5H+1qn6jNb+S5MqqOtaWZo639llg\n45y7bwCOnv6YVbUH2AMwPT39thcCSTpb5+tplAsZctZNgL3AC1X1H+Yc2g/saNs7gIfntN/Wzr7Z\nCpw8tcQjSVp5Q2b0Hwb+DvD1JE+3tn8K3AU8mGQncBi4pR17BLgemAHeAG4fa8WSzjsuqy7PokFf\nVf+T+dfdAbbN07+AO5ZZlyRpTPxkrCR1zmvdSDpn+CbqZDijl6TOGfSS1DmDXpI6Z9BLUud8M1bS\nmuWbt8M4o5ekzjmjH8BP5Ulay5zRS1LnDHpJ6pxBL0mdc41+GVy7l7QWOKOXpM4Z9JLUOYNekjpn\n0EtS54Z8Z+xnkxxP8uyctkuSPJrkxXZ7cWtPknuTzCR5Jsk1kyxekrS4IWfd/DLwH4H757TtBg5U\n1V1Jdrf9TwPXAVvaz4eA+9rtecWzcSSdSxad0VfVV4BXT2veDuxr2/uAm+a0318jB4F1Sa4cV7GS\npKU72/Por6iqYwBVdSzJ5a19PXBkTr/Z1nbs7EvshzN9Sath3G/GZp62mrdjsivJoSSHTpw4MeYy\nJEmnnG3Qv3JqSabdHm/ts8DGOf02AEfne4Cq2lNV01U1PTU1dZZlSJIWc7ZBvx/Y0bZ3AA/Pab+t\nnX2zFTh5aolHkrQ6Fl2jT/I54CPAZUlmgc8AdwEPJtkJHAZuad0fAa4HZoA3gNsnULMkaQkWDfqq\n+sQCh7bN07eAO5ZblCRpfPxkrCR1zqCXpM55PfpzgOfXS5okZ/SS1DmDXpI6Z9BLUucMeknqnEEv\nSZ3zrJtzmGfjSBoHg34N8gVA0lK4dCNJnXNG3xFn+pLm44xekjpn0EtS51y6OQ8stKRzJi73SP0w\n6DWvpb44+MIgnbtcupGkzk0k6JN8PMk3kswk2T2J55AkDTP2pZskFwC/APwoMAt8Ncn+qnp+3M+l\nc8dST+30VNC3nM17KNJSTGKN/lpgpqpeAkjyeWA7YNCfh5YaYuN6b8AXEuktkwj69cCROfuzwIcm\n8DzSxF9IzmSpLxrO3LVaJhH0maet3tYp2QXsart/nOQbZ/l8lwF/eJb3Xasc8zkgd0/8Kc65Ma+A\n827MuXtZY/6rQzpNIuhngY1z9jcAR0/vVFV7gD3LfbIkh6pqermPs5Y45vODYz4/rMSYJ3HWzVeB\nLUmuSnIRcCuwfwLPI0kaYOwz+qp6M8k/AH4buAD4bFU9N+7nkSQNM5FPxlbVI8Ajk3jseSx7+WcN\ncsznB8d8fpj4mFP1tvdJJUkd8RIIktS5NRP0i11WIck7kzzQjj+RZPPKVzleA8Z8Z5LnkzyT5ECS\nQadancuGXj4jyc1JKsmaP0NjyJiT/Hj7XT+X5NdWusZxG/Bve1OSx5M81f59X78adY5Lks8mOZ7k\n2QWOJ8m97b/HM0muGWsBVXXO/zB6U/ebwPcAFwG/C/zAaX3+PvCLbftW4IHVrnsFxvwjwLvb9k+e\nD2Nu/d4LfAU4CEyvdt0r8HveAjwFXNz2L1/tuldgzHuAn2zbPwC8vNp1L3PMPwxcAzy7wPHrgf/G\n6HNIW4Enxvn8a2VG/5eXVaiqPwVOXVZhru3Avrb9ELAtyXwf3lorFh1zVT1eVW+03YOMPrOwlg35\nPQP8K+DfAN9eyeImZMiY/y7wC1X1GkBVHV/hGsdtyJgL+O62/T7m+SzOWlJVXwFePUOX7cD9NXIQ\nWJfkynE9/1oJ+vkuq7B+oT5V9SZwErh0RaqbjCFjnmsnoxnBWrbomJP8ILCxqr64koVN0JDf8/cC\n35vkfyU5mOTjK1bdZAwZ8z8HfiLJLKMz+D61MqWtmqX+/74ka+WLR4ZcVmHQpRfWkMHjSfITwDTw\nNyda0eSdccxJvgO4B/jkShW0Aob8ni9ktHzzEUZ/tf2PJB+oqtcnXNukDBnzJ4Bfrqp/n+SHgF9p\nY/6LyZe3KiaaX2tlRj/ksgp/2SfJhYz+3DvTn0rnukGXkkjyMeCfATdW1Z+sUG2TstiY3wt8APhy\nkpcZrWXuX+NvyA79t/1wVf1ZVf0+8A1Gwb9WDRnzTuBBgKr6HeBdjK6D06tB/7+frbUS9EMuq7Af\n2NG2bwYeq/Yuxxq16JjbMsZ/YhTya33dFhYZc1WdrKrLqmpzVW1m9L7EjVV1aHXKHYsh/7Z/k9Eb\n7yS5jNFSzksrWuV4DRnzYWAbQJLvZxT0J1a0ypW1H7itnX2zFThZVcfG9eBrYummFrisQpJ/CRyq\nqv3AXkZ/3s0wmsnfunoVL9/AMf9b4LuAX2/vOx+uqhtXrehlGjjmrgwc828DP5bkeeDPgX9UVd9a\nvaqXZ+CYfxb4z0l+htESxifX8sQtyecYLb1d1t53+AzwDoCq+kVG70NcD8wAbwC3j/X51/B/O0nS\nAGtl6UaSdJYMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOvf/AZN8bY3NABfbAAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a48e96eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(P_x.rvs(10000), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleParametricSampler(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(SimpleParametricSampler, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(in_dim, 50),\n",
    "            nn.Dropout(0.2), # Dropout injects discrete noise\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(50, 50),\n",
    "            nn.Dropout(0.2), # Dropout injects discrete noise\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(50, 50),\n",
    "            nn.Dropout(0.2), # Dropout injects discrete noise\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(50, out_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, batchsize):\n",
    "        # Start with mul\n",
    "        noise = Variable(torch.randn((batchsize, self.in_dim)), requires_grad=False)\n",
    "        return self.network(noise) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleParametricSampler(10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD8CAYAAACCRVh7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZJEkAABZ/w+v7HRsvMYJjgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f79fc3ba160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parametric Model - initial state\n",
    "rnd = model.forward(3000).detach().numpy()\n",
    "plt.hist2d(rnd[:, 0], rnd[:, 1], bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngy9JTRh8SWrC4EtSEwZfkpow+JLUxP8CYo4hELkTGoAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a440f36d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Multimodal Mixture Model with very limited support in second dimension\n",
    "plt.hist2d(P_x.rvs(2000), np.ones(2000), bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WassersteinDistanceLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, distance, nbatch, nsamples):\n",
    "        self.distance = distance\n",
    "        self.nsamples = nsamples\n",
    "        self.nbatch = nbatch\n",
    "        self.register_buffer('distance_matrix_xx', torch.tensor((nsamples,nsamples,nbatch)), requires_grad=False)\n",
    "        self.register_buffer('distance_matrix_xy', torch.tensor((nsamples,nsamples,nbatch)), requires_grad=False)\n",
    "        self.register_buffer('distance_matrix_yy', torch.tensor((nsamples,nsamples,nbatch)), requires_grad=False)\n",
    "        self.register_buffer('distance_matrix_yx', torch.tensor((nsamples,nsamples,nbatch)), requires_grad=False)\n",
    "        \n",
    "        self.register_buffer('nearest_neighbour_xx', torch.IntTensor((nbatch,nsamples)))\n",
    "        self.register_buffer('nearest_neighbour_yy', torch.IntTensor((nbatch,nsamples)))\n",
    "        self.register_buffer('nearest_neighbour_yy', torch.IntTensor((nbatch,nsamples)))\n",
    "        self.register_buffer('nearest_neighbour_yx', torch.IntTensor((nbatch,nsamples)))\n",
    "        \n",
    "    def precompute_distances(self, samples_a, samples_b, target, maxout_same):\n",
    "        for a in range(self.nsamples):\n",
    "            for b in range(self.nsamples):\n",
    "                batch_a_ = samples_a[a]\n",
    "                batch_b = samples_b[b]\n",
    "                batch_distances = self.distance(batch_a, batch_b)\n",
    "                target[a,b,:].set_(batch_distances.data)\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    def forward(self, sx, sy):\n",
    "        \"\"\"\n",
    "        Precompute Nearest Neighbours, Densities and Distance Matrices for two sample lists \n",
    "        :param samples_x: Sample list of distribution P_x. Dimensions should be interpreted as N-Samples x N-Batch x[...]\n",
    "        :param samples_y: Sample list of distribution P_y. Dimensions should be interpreted as N-Samples x N-Batch x[...]\n",
    "        :returns averaged Wasserstein Distance Estimate\n",
    "        \"\"\"\n",
    "        assert(sx.size()[0]==sy.size()[0]==self.nsamples)\n",
    "        assert(sx.size()[1]==sy.size()[1]==self.nbatch)\n",
    "        self.precompute_distances(sx, sx, self.distance_matrix_xx)\n",
    "        self.precompute_distances(sx, sy, self.distance_matrix_xy)\n",
    "        self.precompute_distances(sy, sy, self.distance_matrix_yy)\n",
    "        self.precompute_distances(sy, sx, self.distance_matrix_yx)\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Paired Distance Estimator\n",
    "\n",
    "If $ P_x = P_y $ we would assume that $ E_{x,y \\sim (P_x, P_y)}[\\hat{p}_{xy}-\\hat{p}_{xx}] = 0 $\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairing Distance Estimator\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to estimate the probability density of $ P_x $ and $ P_y $ based on these samples respectively, we will proceed as follows.\n",
    "\n",
    "###### Precompute all pairwise distances between samples\n",
    " \n",
    "$$ d^{xx}_{ij} = d(x_i, x_j) $$\n",
    "$$ d^{yy}_{ij} = d(x_i, x_j) $$\n",
    "$$ d^{xy}_{ij} = d^{yx}_{ji} = d(x_i, y_j) $$\n",
    "\n",
    "###### Solve the stable marriage problem\n",
    "\n",
    "Next, we build best matching pairs by solving a [Stable Marriage Problem](https://en.wikipedia.org/wiki/Stable_marriage_problem), finding the best unmatched partner for each sample both from the own list of samples and the other list of samples, where each sample can only be married to one partner from the own distribution and to one partner of the other distribution, with preference being determined by distance (preferring lower distance), breaking preference ties at random.\n",
    "\n",
    "We arrive at two lists of matched sample pairs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that given $ \\theta $ we can easily sample from $ P_\\theta $, but we do not assume that we can calculate a density for it. So $ P_\\theta $ might contain arbitrary sources of discrete and continuous randomness such as Dropout-Layers in training mode (as in [Yarin Gal: Dropout as a Bayesian Approximation](https://arxiv.org/pdf/1506.02142.pdf) ) as well as continous random variables, as long as we have a training procedure and we can easily generate i.i.d samples.\n",
    "\n",
    "This means we could also plug in and combine alternative probabilistic graphical models (PGMs) such as CRFs, RBMs, Deep Belief Nets, Bayesian Networks, HMMs, Dynamic Bayesian Networks and their hybrids. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## References\n",
    "\n",
    " * [Wang Q Kulkarni S Verdú S: A Nearest-Neighbor Approach to Estimating Divergence between Continuous Random Vectors](https://www.princeton.edu/~verdu/nearest.neigh.pdf)\n",
    " * [D. O. Loftsgaarden, C. P. Quesenberry: A nonparametric estimate of a multivariate density function](https://projecteuclid.org/euclid.aoms/1177700079)\n",
    " * [Martin Arjovsky, Soumith Chintala, Léon Bottou: Wasserstein GAN](https://arxiv.org/abs/1701.07875)\n",
    " * [Wasserstein GAN Read Through](https://www.alexirpan.com/2017/02/22/wasserstein-gan.html)\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
